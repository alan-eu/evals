{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Building an ECN Eval\n",
    "\n",
    "This notebook shows how to build and run an eval following instructions in docs/build-eval.md\n",
    "Inspiration taken from https://github.com/alan-eu/evals/blob/main/examples/mmlu.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# Assuming this notebook is in examples/\n",
    "registry_path = os.path.join(os.getcwd(), \"../evals/registry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "HF_TOKEN = \"...\"\n",
    "dataset = datasets.load_dataset(\"Alan-health/ecn\", token=HF_TOKEN)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "sys_msg = \"Vous êtes un expert médical. Vous devez répondre à des questions médicales à choix multiple. Choisissez les réponses correctes parmi les réponses proposées, indiquées par les lettres A, B, C, D ou E. Si la bonne réponse est la réponse A, répondez simplement 'A'. Les questions peuvents avoir plusieurs réponses. Dans ce cas, répondez avec toutes les réponses, séparées par une virgule, par example 'B,D,E'.\"\n",
    "\n",
    "\n",
    "def create_chat_prompt(sample):\n",
    "    user_prompt = (\n",
    "        f\"{sample['question']}\\n\"\n",
    "        f\"A: {sample['answer_A']}\\n\"\n",
    "        f\"B: {sample['answer_B']}\\n\"\n",
    "        f\"C: {sample['answer_C']}\\n\"\n",
    "        f\"D: {sample['answer_D']}\\n\"\n",
    "        f\"E: {sample['answer_E']}\\n\"\n",
    "        f\"Réponse:\"\n",
    "    )\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": sys_msg},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "def create_chat_example(sample):\n",
    "    \"\"\"\n",
    "    Form few-shot prompts in the recommended format: https://github.com/openai/openai-python/blob/main/chatml.md#few-shot-prompting\n",
    "    \"\"\"\n",
    "    user_prompt = (\n",
    "        f\"{sample['question']}\\n\"\n",
    "        f\"A: {sample['answer_A']}\\n\"\n",
    "        f\"B: {sample['answer_B']}\\n\"\n",
    "        f\"C: {sample['answer_C']}\\n\"\n",
    "        f\"D: {sample['answer_D']}\\n\"\n",
    "        f\"E: {sample['answer_E']}\\n\"\n",
    "        f\"Réponse:\"\n",
    "    )\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": user_prompt, \"name\": \"example_user\"},\n",
    "        {\"role\": \"system\", \"content\": sample['Correct answer'], \"name\": \"example_assistant\"},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "\n",
    "registry_yaml = {}\n",
    "\n",
    "subject_path = os.path.join(registry_path, \"data\", \"ecn\")\n",
    "os.makedirs(subject_path, exist_ok=True)\n",
    "\n",
    "# Create few-shot prompts\n",
    "few_shot_dataset = dataset['train'].filter(lambda s: s['question_year'] == 2019 and not s['Has picture']).map(lambda example: {'sample': create_chat_example(example), **example})\n",
    "few_shot_path = os.path.join(registry_path, \"data\", \"ecn\", \"few_shot.jsonl\")\n",
    "with open(few_shot_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for example in few_shot_dataset.select(range(4)):\n",
    "        f.write(json.dumps(example, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# Create test prompts and ideal completions\n",
    "eval_dataset = dataset['train'].filter(lambda s: s['question_year'] == 2020 and not s['Has picture']).map(lambda example: {'input': create_chat_prompt(example), \"ideal\": example['Correct answer'], **example})\n",
    "samples_path = os.path.join(registry_path, \"data\", \"ecn\", \"samples.jsonl\")\n",
    "with open(samples_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for example in eval_dataset:\n",
    "        f.write(json.dumps(example, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "eval_id = f\"match_ecn\"\n",
    "\n",
    "registry_yaml[eval_id] = {\n",
    "    \"id\": f\"{eval_id}.test.v1\",\n",
    "    \"metrics\": [\"accuracy\", \"total_score\", \"average_score\", \"valid_format\"]\n",
    "}\n",
    "registry_yaml[f\"{eval_id}.test.v1\"] = {\n",
    "    \"class\": \"evals.elsuite.ecn:Ecn\",\n",
    "    \"args\": {\n",
    "        \"samples_jsonl\": samples_path,\n",
    "        \"few_shot_jsonl\": few_shot_path,\n",
    "        \"num_few_shot\": 4,\n",
    "    }\n",
    "}\n",
    "yaml_path = os.path.join(registry_path, \"evals\", \"match_ecn.yaml\")\n",
    "with open(yaml_path, \"w\") as f:\n",
    "    yaml.dump(registry_yaml, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This will generate a JSONL which will record samples and logs and store it in /tmp/evallogs\n",
    "!oaieval gpt-3.5-turbo match_ecn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oss_evals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
